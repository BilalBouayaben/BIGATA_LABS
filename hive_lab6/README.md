# Laboratoire 6 ‚Äî Apache Hive & Data Warehousing

## üìÑ Documentation compl√®te disponible dans le fichier "CR_Bouayaben_Bilal_TP6_Hive.pdf"

---

## üîß Pr√©requis Techniques

### Configuration de l'Environnement
- **R√©pertoire de donn√©es (h√¥te) :** `C:\Users\lenovo\hadoop_project\hive_data`
  
  **Fichiers requis :**
  - `clients.txt`
  - `hotels.txt`
  - `reservations.txt`

- **Conteneur Hive :** Instance `hiveserver2-standalone` avec montage du volume h√¥te sur `/shared_volume`

### V√©rifications Pr√©alables
1. Assurez-vous que tous les fichiers de donn√©es sont pr√©sents dans le r√©pertoire h√¥te
2. V√©rifiez le montage correct du volume dans le conteneur
3. Confirmez la disponibilit√© de HiveServer2 sur le port 10000

---

## üöÄ Ex√©cution des Scripts HiveQL

### S√©quence d'Ex√©cution (Ordre Obligatoire)

#### 1Ô∏è‚É£ Cr√©ation des Sch√©mas et Tables
```bash
docker exec -it hiveserver2-standalone bash -c \
  "beeline -u 'jdbc:hive2://localhost:10000' -n scott -p tiger \
   -f /shared_volume/lab6_hive/Creation.hql"
```

**Fonctionnalit√©s :**
- D√©finition des tables externes et manag√©es
- Configuration du partitionnement
- Mise en place du bucketing pour optimisation

#### 2Ô∏è‚É£ Chargement des Donn√©es
```bash
docker exec -it hiveserver2-standalone bash -c \
  "beeline -u 'jdbc:hive2://localhost:10000' -n scott -p tiger \
   -f /shared_volume/lab6_hive/Loading.hql"
```

**Important :** Avant d'ex√©cuter cette √©tape, copiez tous les fichiers `.txt` dans le r√©pertoire configur√© sur l'h√¥te.

**Actions effectu√©es :**
- Ingestion des donn√©es depuis les fichiers sources
- Population des tables partitionn√©es
- Chargement dans les buckets configur√©s

#### 3Ô∏è‚É£ Requ√™tes Analytiques
```bash
docker exec -it hiveserver2-standalone bash -c \
  "beeline -u 'jdbc:hive2://localhost:10000' -n scott -p tiger \
   -f /shared_volume/lab6_hive/Queries.hql"
```

**Analyses r√©alis√©es :**
- Agr√©gations complexes (GROUP BY, HAVING)
- Jointures entre tables multiples
- Fonctions de fen√™trage (window functions)
- Requ√™tes analytiques avanc√©es

---

## üìä R√©sultats & Validation

Le document PDF annex√© contient :
- Captures d'√©cran des r√©sultats de chaque requ√™te
- M√©triques de performance (temps d'ex√©cution)
- Analyse des plans d'ex√©cution (EXPLAIN)
- Validation des optimisations appliqu√©es

---

## üí° Notes Techniques

### Optimisations Impl√©ment√©es

**Partitionnement :**
- D√©coupage logique des tables par colonnes cl√©s
- Am√©lioration des performances pour les requ√™tes filtr√©es
- R√©duction du volume de donn√©es scann√©es

**Bucketing (Clustering) :**
- Distribution uniforme des donn√©es dans des fichiers
- Optimisation des jointures (map-side joins)
- Am√©lioration du sampling et de l'√©chantillonnage

### Bonnes Pratiques

**Pr√©paration des Donn√©es :**
- ‚ö†Ô∏è **Supprimer les en-t√™tes CSV** avant le chargement
- Alternative : Utiliser `TBLPROPERTIES ("skip.header.line.count"="1")`
- V√©rifier l'encodage des fichiers (UTF-8 recommand√©)
- Valider les d√©limiteurs de champs

**Gestion des M√©tadonn√©es :**
- Les tables externes pr√©servent les donn√©es sources apr√®s suppression
- Les tables manag√©es (internes) suppriment les donn√©es avec DROP TABLE
- Utiliser MSCK REPAIR TABLE pour synchroniser les partitions

**Performance :**
- Activer la vectorisation : `SET hive.vectorized.execution.enabled = true;`
- Optimiser les jointures : `SET hive.auto.convert.join = true;`
- Utiliser le format ORC ou Parquet pour les grandes volum√©tries

---

**D√©velopp√© par : Bouayaben Bilal**
