# Laboratoire 4 ‚Äî Apache HBase

**R√©alis√© par : Bouayaben Bilal** - Ann√©e Universitaire 2025-2026

## üìÑ Objectifs du TP

Ce laboratoire couvre les aspects fondamentaux d'Apache HBase, une base de donn√©es NoSQL distribu√©e construite sur Hadoop HDFS.

### üéØ Comp√©tences vis√©es :
- ‚úÖ Installation et configuration d'Apache HBase
- ‚úÖ Premi√®re utilisation du shell HBase
- ‚úÖ Utilisation de l'API HBase en Java
- ‚úÖ Chargement et manipulation de fichiers
- ‚úÖ Traitement de donn√©es avec Apache Spark

---

## üèóÔ∏è Architecture

**Apache HBase** est une base de donn√©es orient√©e colonnes open-source, distribu√©e et versionn√©e. Elle fournit des fonctionnalit√©s de type BigTable de Google sur la base de Hadoop HDFS.

**HBase** offre √©galement une API en Java permettant de pouvoir interagir avec les donn√©es de la base.

---

## üìã Pr√©requis

### Infrastructure Docker
Assurez-vous que les conteneurs Hadoop sont lanc√©s :

```powershell
# Depuis le dossier docker_setup
cd ..\docker_setup
docker-compose up -d

# V√©rifier que les conteneurs sont actifs
docker ps
```

Vous devez avoir :
- `hadoop-master` (conteneur principal)
- `hadoop-slave1` et `hadoop-slave2` (workers)

---

## üöÄ Installation HBase

### √âtape 1 : T√©l√©charger HBase

HBase peut √™tre t√©l√©charg√© depuis le cluster Hadoop (g√©n√©ralement pr√©-install√© dans l'image `hadoop-spark-jupyter`) ou vous pouvez utiliser un conteneur d√©di√© HBase.

**Option 1 : Utiliser l'image avec HBase int√©gr√©**
```bash
# Se connecter au conteneur master
docker exec -it hadoop-master bash

# V√©rifier si HBase est install√©
which hbase
```

**Option 2 : Utiliser un conteneur HBase standalone**
```bash
# Lancer un conteneur HBase standalone
docker run -itd \
  --name hbaseserver-standalone \
  --hostname hbaseserver-standalone \
  --network docker_setup_hadoop-network \
  -p 16010:16010 \
  -p 16030:16030 \
  -v C:/Users/lenovo/hadoop_project/BIGDATA_ENGINEERING_LABS:/shared_volume \
  harisekhon/hbase:1.4
```

### √âtape 2 : D√©marrer HBase

```bash
# Si HBase est dans le conteneur hadoop-master
docker exec -it hadoop-master bash

# Lancer HBase (si non automatique)
cd /usr/local/hbase
./bin/start-hbase.sh

# V√©rifier que HBase est lanc√©
jps
# Vous devez voir : HMaster
```

---

## üíª Premi√®re Utilisation - HBase Shell

### Lancer le shell HBase

```bash
# Depuis le conteneur
hbase shell
```

### Commandes de base

#### Cr√©er une table
```ruby
# Syntaxe : create 'nom_table', 'famille_colonnes'
create 'customers', 'customer', 'sales'
```

#### Lister les tables
```ruby
list
```

#### D√©crire une table
```ruby
describe 'customers'
```

#### Ins√©rer des donn√©es
```ruby
# put 'table', 'row_key', 'column_family:column', 'value'
put 'customers', '101', 'customer:name', 'John White'
put 'customers', '101', 'customer:city', 'Los Angeles, CA'
put 'customers', '101', 'sales:product', 'Lamps'
put 'customers', '101', 'sales:amount', '$200.00'

put 'customers', '102', 'customer:name', 'Jane Brown'
put 'customers', '102', 'customer:city', 'Atlanta, GA'
put 'customers', '102', 'sales:product', 'Lamps'
put 'customers', '102', 'sales:amount', '$200.00'

put 'customers', '103', 'customer:name', 'Bill Green'
put 'customers', '103', 'customer:city', 'Pittsburgh, PA'
put 'customers', '103', 'sales:product', 'Desk'
put 'customers', '103', 'sales:amount', '$500.00'

put 'customers', '104', 'customer:name', 'Jack Black'
put 'customers', '104', 'customer:city', 'St. Louis, MO'
put 'customers', '104', 'sales:product', 'Bed'
put 'customers', '104', 'sales:amount', '$1,600.00'
```

#### Lire des donn√©es
```ruby
# Lire toute la table
scan 'customers'

# Lire une ligne sp√©cifique
get 'customers', '101'

# Lire une colonne sp√©cifique
get 'customers', '101', 'customer:name'
```

#### Mettre √† jour des donn√©es
```ruby
# Mettre √† jour une valeur (m√™me syntaxe que put)
put 'customers', '101', 'sales:amount', '$250.00'
```

#### Supprimer des donn√©es
```ruby
# Supprimer une colonne
delete 'customers', '101', 'sales:amount'

# Supprimer une ligne compl√®te
deleteall 'customers', '101'
```

#### Supprimer une table
```ruby
# D√©sactiver la table avant de la supprimer
disable 'customers'
drop 'customers'
```

---

## üîß Utilisation de l'API HBase (Java)

### Configuration Maven

Ajouter les d√©pendances HBase dans `pom.xml` :

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.hbase</groupId>
        <artifactId>hbase-client</artifactId>
        <version>2.4.9</version>
    </dependency>
    <dependency>
        <groupId>org.apache.hbase</groupId>
        <artifactId>hbase-common</artifactId>
        <version>2.4.9</version>
    </dependency>
</dependencies>
```

### Exemple : Cr√©er une table avec Java

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.TableName;
import org.apache.hadoop.hbase.client.*;

public class HBaseExample {
    public static void main(String[] args) throws Exception {
        Configuration config = HBaseConfiguration.create();
        config.set("hbase.zookeeper.quorum", "localhost");
        config.set("hbase.zookeeper.property.clientPort", "2181");
        
        Connection connection = ConnectionFactory.createConnection(config);
        Admin admin = connection.getAdmin();
        
        // Cr√©er une table
        TableName tableName = TableName.valueOf("test_table");
        TableDescriptorBuilder builder = TableDescriptorBuilder.newBuilder(tableName);
        builder.setColumnFamily(ColumnFamilyDescriptorBuilder.of("cf1"));
        
        admin.createTable(builder.build());
        
        System.out.println("Table cr√©√©e avec succ√®s !");
        
        admin.close();
        connection.close();
    }
}
```

---

## üìä Chargement de Fichiers

### Bulk Load avec ImportTsv

```bash
# Pr√©parer un fichier CSV
# Format : row_key,column_family:column,value

# Charger dans HBase
hbase org.apache.hadoop.hbase.mapreduce.ImportTsv \
  -Dimporttsv.separator=',' \
  -Dimporttsv.columns=HBASE_ROW_KEY,customer:name,customer:city,sales:product,sales:amount \
  customers \
  hdfs://hadoop-master:9000/user/data/customers.csv
```

---

## üß™ Exercices Pratiques

### Exercice 1 : Manipulation de base
1. Cr√©er une table `products` avec deux familles de colonnes : `info` et `stock`
2. Ins√©rer 5 produits avec leurs informations
3. Afficher tous les produits
4. Mettre √† jour le stock d'un produit
5. Supprimer un produit

### Exercice 2 : API Java
1. Cr√©er un programme Java qui se connecte √† HBase
2. Cr√©er une table programmatiquement
3. Ins√©rer des donn√©es
4. Lire et afficher les donn√©es

### Exercice 3 : Traitement avec Spark
1. Charger des donn√©es depuis HBase dans Spark
2. Effectuer des agr√©gations
3. Sauvegarder les r√©sultats dans une nouvelle table HBase

---

## üìù Notes Techniques

### Architecture HBase
- **HMaster** : Coordonne le cluster HBase
- **RegionServer** : G√®re les r√©gions (partitions de tables)
- **ZooKeeper** : Coordination et configuration
- **HDFS** : Stockage sous-jacent

### Familles de Colonnes
- Regroupement logique de colonnes
- D√©finies √† la cr√©ation de la table
- Optimisation du stockage et des performances

### Row Key Design
- **Critique** pour les performances
- √âviter les hotspots (concentration sur un seul RegionServer)
- Utiliser des pr√©fixes distribu√©s si n√©cessaire

### Bonnes Pratiques
- Limiter le nombre de familles de colonnes (g√©n√©ralement 1-3)
- Utiliser des Row Keys bien distribu√©es
- Activer la compression pour r√©duire l'espace disque
- Utiliser le bloom filter pour am√©liorer les lectures

---

## üîó Ressources Utiles

- [Documentation officielle HBase](https://hbase.apache.org/)
- [HBase Shell Reference](https://hbase.apache.org/book.html#shell)
- [HBase Java API](https://hbase.apache.org/apidocs/)

---

**D√©velopp√© par : Bouayaben Bilal**
