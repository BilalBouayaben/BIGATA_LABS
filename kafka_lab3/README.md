# Laboratoire 3 ‚Äî Apache Kafka & Streaming en Temps R√©el

**R√©alis√© par : Bouayaben Bilal** - 3A BI&A

## üìÑ Documentation compl√®te disponible dans le fichier "CR_Bouayaben_Bilal_TP3_Kafka.pdf"

---

Ce laboratoire explore l'√©cosyst√®me Apache Kafka pour le traitement de flux de donn√©es en temps r√©el et la construction de pipelines de donn√©es √©v√©nementielles.

## üì¶ Contenu du Module

### Architecture des Sources Java
R√©pertoire : `kafka_lab/src/main/java/edu/ensias/kafka/`

**Composants de Base :**
  - **`EventProducer`** & **`EventConsumer`** : Impl√©mentations fondamentales producteur/consommateur
  
**Applications Interactives :**
  - **`WordProducer`** : Interface en ligne de commande - capture clavier et publication sur topic Kafka
  - **`WordCountConsumer`** : Consommateur avec agr√©gation en m√©moire - affichage des statistiques par mot

**Traitement de Flux (Streams) :**
  - **`WordCountApp`** : Application Kafka Streams stateful avec state store local pour comptage distribu√©

### Configuration & Build
- **`pom.xml`** : Configuration Maven avec g√©n√©ration d'un fat-jar (`*-jar-with-dependencies.jar` dans `target/`)
- **`docker-compose.yml`** : Orchestration Docker pour Kafka-UI (interface de monitoring)

## üöÄ Guide de D√©ploiement

### √âtape 1 : Compilation du Projet
Ex√©cuter sur la machine h√¥te :

```powershell
cd lab3_kafka/kafka_lab
mvn clean package
```

### √âtape 2 : Distribution de l'Artefact
Copier le JAR assembl√© vers le volume partag√© du cluster :

```powershell
Copy-Item -Path .\target\*jar-with-dependencies*.jar -Destination "C:\Users\lenovo\hadoop_project\kafka" -Force
```
> **Note :** Adapter le chemin de destination selon votre configuration

### √âtape 3 : Configuration des Topics Kafka
Depuis le conteneur `hadoop-master` :

```bash
# Cr√©ation du topic d'entr√©e
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --create --topic input-topic --partitions 1 --replication-factor 1

# Cr√©ation du topic de sortie
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 \
  --create --topic output-topic --partitions 1 --replication-factor 1
```

### √âtape 4 : Lancement des Applications

#### Producteur Interactif (saisie clavier) :
```bash
java -cp /shared_volume/kafka/*jar-with-dependencies*.jar \
  edu.ensias.kafka.WordProducer input-topic localhost:9092
```

#### Consommateur avec Comptage :
```bash
java -cp /shared_volume/kafka/*jar-with-dependencies*.jar \
  edu.ensias.kafka.WordCountConsumer output-topic localhost:9092
```

### √âtape 5 : Tests via Console Kafka

#### Publication manuelle sur input-topic :
```bash
/usr/local/kafka/bin/kafka-console-producer.sh \
  --broker-list localhost:9092 --topic input-topic
```

#### Consommation depuis output-topic (avec affichage des cl√©s) :
```bash
/usr/local/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 --topic output-topic \
  --from-beginning --property print.key=true
```

## üèóÔ∏è Configuration Avanc√©e - Cluster Multi-Brokers

### Architecture Distribu√©e
Le conteneur `hadoop-master` h√©berge une installation Kafka (typiquement dans `/usr/local/kafka`).

### Mise en Place d'un Cluster
Pour d√©ployer un cluster Kafka haute disponibilit√© :
1. Cr√©er des fichiers de configuration suppl√©mentaires :
   - `server-one.properties` (port 9093)
   - `server-two.properties` (port 9094)
2. Lancer plusieurs instances de brokers
3. Cr√©er des topics avec r√©plication :
   ```bash
   --replication-factor 2
   ```

## üñ•Ô∏è Interface de Monitoring : Kafka-UI

Le fichier `docker-compose.yml` inclut un service **Kafka-UI** accessible sur le port **8081** de l'h√¥te.

**Lancement :**
```powershell
docker-compose up -d
```

**Acc√®s Web :** [http://localhost:8081](http://localhost:8081)

**Fonctionnalit√©s :**
- Inspection des topics, partitions et offsets
- Visualisation des messages en temps r√©el
- Monitoring des groupes de consommateurs
- Gestion du cluster Kafka

## ‚ö†Ô∏è Notes Techniques Importantes

### Persistance des Donn√©es
- Le consommateur `WordCountConsumer` maintient les compteurs **uniquement en m√©moire**
- Les donn√©es sont perdues au red√©marrage de l'application
- Pour une persistance, envisager Kafka Streams avec state store ou une base externe

### Optimisation du Build
Pour g√©n√©rer des JARs d√©di√©s avec points d'entr√©e sp√©cifiques :
- Configurer le plugin `maven-shade-plugin` dans `pom.xml`
- D√©finir l'attribut `Main-Class` pour chaque ex√©cutable
- G√©n√©rer des artefacts s√©par√©s (producer.jar, consumer.jar, etc.)

### Bonnes Pratiques
- Utiliser des groupes de consommateurs pour le load balancing
- Configurer des strat√©gies de s√©rialisation appropri√©es (Avro, JSON, Protobuf)
- Monitorer les m√©triques de latence et de throughput
- Impl√©menter une gestion d'erreurs robuste (retry, dead-letter queues)

---

**D√©velopp√© par : Bouayaben Bilal**
